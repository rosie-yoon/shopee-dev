# shopee_creator/creation_steps.py
# -*- coding: utf-8 -*
from __future__ import annotations

from typing import List, Dict, Optional
import io
import csv
import re
from io import BytesIO

import gspread
from gspread.cell import Cell
from gspread.utils import rowcol_to_a1
from gspread.exceptions import WorksheetNotFound
import pandas as pd  # ëª…ì‹œì  ì„í¬íŠ¸

# âš ï¸ ì¤‘ìš”: utils_creator.pyê°€ join_urlì„ í¬í•¨í•˜ê³  ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì„í¬íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
from .utils_creator import (
    header_key, top_of_category, get_tem_sheet_name,
    with_retry, safe_worksheet, get_env,
    forward_fill_by_group, # join_url ì œê±°ë¨
    extract_sheet_id, _is_true # ğŸš¨ _is_true ì„í¬íŠ¸
)


# -------------------------------------------------------------------
# ë‚´ë¶€ í—¬í¼ (C5ìš©)
# -------------------------------------------------------------------

def _find_col_index(keys: List[str], name: str, extra_alias: List[str] = []) -> int:
    """í—¤ë” í‚¤ ëª©ë¡(keys=header_key ì ìš©ëœ ë¦¬ìŠ¤íŠ¸)ì—ì„œ name ë˜ëŠ” aliasë¥¼ ì°¾ìŒ"""
    tgt = header_key(name)
    aliases = [header_key(a) for a in extra_alias] + [tgt]
    # ì •í™• ë§¤ì¹­
    for i, k in enumerate(keys):
        if k in aliases:
            return i
    # ë¶€ë¶„ ë§¤ì¹­
    for i, k in enumerate(keys):
        if any(a and a in k for a in aliases):
            return i
    return -1


def _pick_index_by_candidates(header_row: List[str], candidates: List[str]) -> int:
    """í—¤ë” í–‰ì—ì„œ í›„ë³´ëª…(ì •ê·œí™”)ìœ¼ë¡œ ê°€ì¥ ê·¸ëŸ´ë“¯í•œ ì¸ë±ìŠ¤ ì°¾ê¸° (ì •í™• > ë¶€ë¶„ ì¼ì¹˜)"""
    keys = [header_key(x) for x in header_row]
    # ì •í™• ì¼ì¹˜
    for cand in candidates:
        ck = header_key(cand)
        for i, k in enumerate(keys):
            if k == ck:
                return i
    # ë¶€ë¶„ ì¼ì¹˜
    for cand in candidates:
        ck = header_key(cand)
        if not ck:
            continue
        for i, k in enumerate(keys):
            if ck in k:
                return i
    return -1


from gspread.exceptions import WorksheetNotFound

def _load_template_dict(ref: gspread.Spreadsheet) -> Dict[str, List[str]]:
    """
    Reference ì‹œíŠ¸ì˜ TemplateDict íƒ­ì—ì„œ
    TopLevel(ì²« ì»¬ëŸ¼) â†’ [í—¤ë”ë“¤] ë§¤í•‘ì„ ë¡œë“œ.
    - íƒ­ì´ ì—†ê±°ë‚˜ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ëª…í™•í•œ ì—ëŸ¬ë¡œ ì¤‘ë‹¨(ë””ë²„ê¹… ìš©ì´)
    """
    ref_sheet = get_env("TEMPLATE_DICT_SHEET_NAME", "TemplateDict")

    # íƒ­ì€ ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•¨: ì—†ìœ¼ë©´ ë°”ë¡œ ì˜ˆì™¸
    try:
        ws = ref.worksheet(ref_sheet)
    except WorksheetNotFound:
        raise WorksheetNotFound(f"Required sheet '{ref_sheet}' not found in '{ref.title}'")

    vals = with_retry(lambda: ws.get_all_values()) or []

    # [DEBUG] ë””ë²„ê·¸ ë¡œê·¸ëŠ” ìœ ì§€ (TemplateDict ë¡œë“œ ê²°ê³¼ í™•ì¸)
    print(f"[TDict][DEBUG] ref='{ref.title}' tab='{ref_sheet}' rows={len(vals)}")
    try:
        print("[TDict][DEBUG] tabs in ref (head):", [w.title for w in ref.worksheets()][:10])
    except Exception:
        pass

    if len(vals) < 2:
        raise RuntimeError(
            f"TemplateDict has no data (rows={len(vals)}) in '{ref.title}'. "
            f"Tab '{ref_sheet}' must have header + at least 1 data row."
        )

    out: Dict[str, List[str]] = {}
    for r in vals[1:]:
        if not r or not (r[0] or "").strip():
            continue
        # í—¤ë” ì •ê·œí™”ëŠ” í•„ìˆ˜: TemplateDictì˜ í‚¤ëŠ” header_key(top_of_category(...))ë¡œ ì°¾ìŒ
        out[header_key(r[0])] = [str(x or "").strip() for x in r[1:]]
    if not out:
        raise RuntimeError("TemplateDict parsed to empty dict. Check first-column values.")
    return out


def _collect_indices(header_row: List[str]) -> Dict[str, int]:
    keys = [header_key(x) for x in header_row]

    def idx(name: str, aliases: List[str] = []) -> int:
        return _find_col_index(keys, name, extra_alias=aliases)

    return {
        "create": idx("create", ["use", "apply"]),
        "variation": idx("variation", ["variationno", "variationintegrationno", "var code", "variation code"]),
        "sku": idx("sku", ["seller_sku"]),
        "brand": idx("brand", ["brandname"]),
        "option_eng": idx("option(eng)", ["optioneng", "option", "option1", "option name", "option for variation 1"]),
        "prod_name": idx("product name", ["item(eng)", "itemeng", "name"]),
        "desc": idx("description", ["product description"]),
        "category": idx("category"),
        "detail_idx": idx("details index", ["detail image count", "details count", "detailindex"]),
    }


# -------------------------------------------------------------------
# C1: TEM_OUTPUT ì‹œíŠ¸ ì¤€ë¹„/ì´ˆê¸°í™”
# -------------------------------------------------------------------

def run_step_C1(sh: gspread.Spreadsheet, ref: Optional[gspread.Spreadsheet]) -> None:
    print("\n[ Create ] Step C1: Prepare TEM_OUTPUT sheet ...")
    tem_name = get_tem_sheet_name()
    try:
        tem_ws = safe_worksheet(sh, tem_name)
        with_retry(lambda: tem_ws.clear())
    except Exception:
        # ì‹œíŠ¸ê°€ ì—†ê±°ë‚˜ í´ë¦¬ì–´ ê¶Œí•œì´ ì—†ì„ ë•Œ(403)ë¥¼ ëŒ€ë¹„í•˜ì—¬ ì‹œíŠ¸ ì¶”ê°€ ì¬ì‹œë„
        tem_ws = with_retry(lambda: sh.add_worksheet(title=tem_name, rows=2000, cols=200))
    with_retry(lambda: tem_ws.update(values=[[""]], range_name="A1"))
    print("C1 Done.")


# -------------------------------------------------------------------
# C2: Collection â†’ TEM_OUTPUT (ë²„í‚· ìƒì„± + Variation ê·¸ë£¹ ê³µë€ ë³´ì •)
# -------------------------------------------------------------------

def run_step_C2(sh: gspread.Spreadsheet, ref: gspread.Spreadsheet) -> None:
    print("\n[ Create ] Step C2: Build TEM from Collection ...")
    tem_name = get_tem_sheet_name()

    template_dict = _load_template_dict(ref)
    print(f"[C2][DEBUG] TemplateDict loaded. top-level count = {len(template_dict)}")

    coll_ws = safe_worksheet(sh, "Collection")
    coll_vals = with_retry(lambda: coll_ws.get_all_values()) or []

    # [DEBUG] Collection ë°ì´í„° ìœ ë¬´/í—¤ë” ê¸¸ì´ í™•ì¸
    print(f"[C2][DEBUG] Collection rows = {len(coll_vals)}"
          f" (header cols = {len(coll_vals[0]) if coll_vals else 0})")

    if not coll_vals or len(coll_vals) < 2:
        print("[C2] Collection ë¹„ì–´ ìˆìŒ. (rows < 2)")
        return

    colmap = _collect_indices(coll_vals[0])
    # [DEBUG] ì£¼ìš” ì»¬ëŸ¼ ì¸ë±ìŠ¤ ë¤í”„
    print("[C2][DEBUG] colmap =", colmap)

    # ì¸ë±ìŠ¤ê°€ ì—†ì„ ê²½ìš° -1ì„ ìœ ì§€
    create_i   = colmap["create"]    if colmap["create"]    >= 0 else -1
    variation_i= colmap["variation"] if colmap["variation"] >= 0 else 1
    sku_i      = colmap["sku"]       if colmap["sku"]       >= 0 else 2
    brand_i    = colmap["brand"]     if colmap["brand"]     >= 0 else 3
    option_i   = colmap["option_eng"]if colmap["option_eng"]>= 0 else 5
    pname_i    = colmap["prod_name"] if colmap["prod_name"] >= 0 else 7
    desc_i     = colmap["desc"]      if colmap["desc"]      >= 0 else 9
    category_i = colmap["category"]  if colmap["category"]  >= 0 else 10
    dcount_i   = colmap["detail_idx"]if colmap["detail_idx"]>= 0 else 11
    
    # create_iê°€ -1ì´ë©´ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í—¤ë” ë¬¸ì œë¡œ ì²˜ë¦¬ ë¶ˆê°€
    if create_i == -1:
        print("[C2] ERROR: 'create' column not found (aliases: create, use, apply). Check Collection sheet header.")
        return

    fill_cols = [variation_i, brand_i, pname_i, desc_i, category_i, dcount_i]

    def _reset_when(row: List[str]) -> bool:
        return not any(str(x or "").strip() for x in row)

    ff_vals = forward_fill_by_group(
        [list(r) for r in coll_vals],
        group_idx=variation_i,
        fill_col_indices=fill_cols,
        reset_when=_reset_when,
    )

    # [DEBUG] forward fill í›„ ë°ì´í„° ìƒ˜í”Œ
    print(f"[C2][DEBUG] forward-filled rows = {len(ff_vals)}")

    # ìµœì¢… ìœ íš¨ í–‰ ì¹´ìš´íŠ¸ (ë””ë²„ê·¸ ìš©)
    create_true_count = sum(
        1 for r in ff_vals[1:] 
        if _is_true((r[create_i] if create_i < len(r) else ""))
    )
    print(f"[C2][DEBUG] Rows where 'create' is True (final check): {create_true_count}")
    
    buckets: Dict[str, Dict[str, List]] = {}
    failures: List[List[str]] = []
    category_missing_count = 0
    toplevel_missing_count = 0


    def set_if_exists(headers: List[str], row: List[str], name: str, value: str):
        idx = _find_col_index([header_key(h) for h in headers], name)
        if idx >= 0:
            row[idx] = value

    created_rows = 0

    # ì‹¤íŒ¨ ì‹œ ë¡œê·¸ë¥¼ ë°”ë¡œ ì¶œë ¥í•  ë¦¬ìŠ¤íŠ¸
    failed_categories_log: List[str] = []

    for r in range(1, len(ff_vals)):
        row = ff_vals[r]
        # ğŸš¨ _is_true í•¨ìˆ˜ ì‚¬ìš©
        if not _is_true(row[create_i] if create_i < len(row) else ""):
            continue  # create=False ëŠ” ìŠ¤í‚µ

        # ì»¬ëŸ¼ ê°’ ì¶”ì¶œ (ì¸ë±ìŠ¤ ì²´í¬ í¬í•¨)
        variation = (row[variation_i] if variation_i < len(row) else "").strip()
        sku       = (row[sku_i]       if sku_i       < len(row) else "").strip()
        brand     = (row[brand_i]     if brand_i     < len(row) else "").strip()
        opt1      = (row[option_i]    if option_i    < len(row) else "").strip()
        pname     = (row[pname_i]     if pname_i     < len(row) else "").strip()
        desc      = (row[desc_i]      if desc_i      < len(row) else "").strip()
        category  = (row[category_i]  if category_i  < len(row) else "").strip()

        if not category:
            pid = variation or sku or f"ROW{r+1}"
            failures.append([pid, "", pname, "CATEGORY_MISSING", f"row={r+1}"])
            category_missing_count += 1
            continue
        
        # utils_creator.pyì—ì„œ ìˆ˜ì •ëœ top_of_category í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆœìˆ˜ ì¹´í…Œê³ ë¦¬ ì´ë¦„ ì¶”ì¶œ
        top_category_raw = top_of_category(category) 
        top_norm = header_key(top_category_raw or "")
        
        # TemplateDictì—ì„œ í—¤ë” ë§¤í•‘ ì‹œë„
        headers = template_dict.get(top_norm)

        if not headers:
            failures.append(["", category, pname, "TEMPLATE_TOPLEVEL_NOT_FOUND",
                             f"top={top_category_raw} (Key: {top_norm})"])
            toplevel_missing_count += 1
            # ğŸš¨ [ê°•ì œ ë””ë²„ê·¸ ë¡œê·¸ ì¶”ê°€] ë§¤ì¹­ ì‹¤íŒ¨í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            if top_category_raw not in failed_categories_log:
                 failed_categories_log.append(f"'{top_category_raw}' (Key: '{top_norm}')")
            continue

        tem_row = [""] * len(headers)
        set_if_exists(headers, tem_row, "category", category)
        set_if_exists(headers, tem_row, "product name", pname)
        set_if_exists(headers, tem_row, "product description", desc)
        set_if_exists(headers, tem_row, "variation integration", variation)
        set_if_exists(headers, tem_row, "variation name1", "Options")
        set_if_exists(headers, tem_row, "option for variation 1", opt1)
        set_if_exists(headers, tem_row, "sku", sku)
        set_if_exists(headers, tem_row, "brand", brand)

        pid = variation or sku or f"ROW{r+1}"
        b = buckets.setdefault(top_norm, {"headers": headers, "pids": [], "rows": []})
        b["pids"].append([pid])
        b["rows"].append(tem_row)
        created_rows += 1

    # ìµœì¢… ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (í•„í„°ë§ ê²°ê³¼ ìš”ì•½)
    print(f"[C2][DEBUG] Filtered summary: Created={created_rows}, Category Missing={category_missing_count}, Toplevel Not Found={toplevel_missing_count}")
    print(f"[C2][DEBUG] Total failures (logged to failure list): {len(failures)}")

    # ğŸš¨ [ì¶”ê°€ëœ ê°•ì œ ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥]
    if failed_categories_log:
         print("\n[C2][ERROR] TEMPLATE DICT MATCH FAILURES:")
         for log in failed_categories_log:
             print(f"  â†’ Missing Top-Level Key: {log}")
         print("---------------------------------------")


    out_matrix: List[List[str]] = []
    for top_key, pack in buckets.items():
        out_matrix.append(["PID"] + pack["headers"])
        out_matrix.extend([pid_row + data_row for pid_row, data_row in zip(pack["pids"], pack["rows"])])
        # [DEBUG] ë²„í‚·ë³„ í–‰ìˆ˜
        print(f"[C2][DEBUG] bucket[{top_key}] rows = {len(pack['rows'])}")

    if out_matrix:
        tem_ws = safe_worksheet(sh, tem_name)
        # TEM_OUTPUT ì‹œíŠ¸ ì—…ë°ì´íŠ¸
        with_retry(lambda: tem_ws.clear())
        max_cols = max(len(r) for r in out_matrix)
        end_a1 = rowcol_to_a1(len(out_matrix), max_cols)
        with_retry(lambda: tem_ws.resize(rows=len(out_matrix) + 10, cols=max_cols + 10))
        with_retry(lambda: tem_ws.update(values=out_matrix, range_name=f"A1:{end_a1}"))
        print(f"[C2] TEM_OUTPUT updated. rows={len(out_matrix)} cols={max_cols}")
    else:
        print("[C2] out_matrix is empty â†’ TEM_OUTPUT ë¯¸ê°±ì‹  (TemplateDict/Collection í™•ì¸ í•„ìš”)")

    # TODO: failures ê¸°ë¡ ì‹œíŠ¸ ì²˜ë¦¬(í•„ìš”ì‹œ)
    print(f"C2 Done. Buckets: {len(buckets)}")

# -------------------------------------------------------------------
# C3: FDA Registration No. ì±„ìš°ê¸°
# -------------------------------------------------------------------

def run_step_C3_fda(sh: gspread.Spreadsheet, ref: gspread.Spreadsheet, overwrite: bool = False) -> None:
    print("\n[ Create ] Step C3: Fill FDA Code ...")

    tem_name = get_tem_sheet_name()
    fda_sheet_name = get_env("FDA_CATEGORIES_SHEET_NAME", "TH Cos")
    fda_header = get_env("FDA_HEADER_NAME", "FDA Registration No.")
    FDA_CODE = "10-1-9999999"  # ê³ ì •ê°’ ì •ì±…

    try:
        fda_ws = safe_worksheet(ref, fda_sheet_name)
        # Aì—´ ì¹´í…Œê³ ë¦¬ ë¡œë“œ
        fda_vals_2d = with_retry(lambda: fda_ws.get_values("A:A", value_render_option="UNFORMATTED_VALUE"))
        # ë¡œë“œëœ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ê·œí™”í•˜ì—¬ ì…‹(set)ìœ¼ë¡œ ë§Œë“¦
        # ğŸš¨ TEM_OUTPUTì˜ ê°’ê³¼ ë™ì¼í•˜ê²Œ ì •ê·œí™”
        target_categories = {str(r[0]).strip().lower() for r in (fda_vals_2d or []) if r and str(r[0]).strip()}
    except Exception as e:
        print(f"[!] '{fda_sheet_name}' íƒ­ ë¡œë“œ ì‹¤íŒ¨: {e}. Step C3 ê±´ë„ˆ<binary data, 2 bytes><binary data, 2 bytes><binary data, 2 bytes>ë‹ˆë‹¤.")
        return

    try:
        tem_ws = safe_worksheet(sh, tem_name)
        vals = with_retry(lambda: tem_ws.get_all_values()) or []
    except WorksheetNotFound:
        print(f"[!] {tem_name} íƒ­ ì—†ìŒ. Step C1/C2 ì„ í–‰ í•„ìš”.")
        return

    if not vals:
        return

    updates: List[Cell] = []
    current_keys, col_category_B, col_fda_B = None, -1, -1

    # TEM_OUTPUT ë°ì´í„° ìˆœíšŒ
    for r0, row in enumerate(vals):
        # í—¤ë” í–‰ ì°¾ê¸°
        if (row[1] if len(row) > 1 else "").strip().lower() == "category":
            current_keys = [header_key(h) for h in row[1:]]
            col_category_B = _find_col_index(current_keys, "category")
            col_fda_B = _find_col_index(current_keys, fda_header)
            continue
        # í—¤ë”ë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
        if not current_keys or col_fda_B < 0 or col_category_B < 0:
            continue

        pid = (row[0] if len(row) > 0 else "").strip()
        if not pid:
            continue

        # Category ê°’ ì¶”ì¶œ (í—¤ë” ì œì™¸í•œ ë°ì´í„° í–‰ì˜ ì¸ë±ìŠ¤ ê¸°ì¤€)
        category_val_raw = (row[col_category_B + 1] if len(row) > (col_category_B + 1) else "").strip()
        
        # ì¹´í…Œê³ ë¦¬ ì •ê·œí™” (ì „ì²´ ê²½ë¡œë¥¼ ì†Œë¬¸ìë¡œ ì‚¬ìš©)
        category_val_normalized = category_val_raw.lower()

        # FDA ëŒ€ìƒ ì¹´í…Œê³ ë¦¬ì¸ì§€ í™•ì¸
        if category_val_normalized and category_val_normalized in target_categories:
            # FDA ì»¬ëŸ¼ì˜ ì‹¤ì œ ì‹œíŠ¸ ì»¬ëŸ¼ ì¸ë±ìŠ¤ (Bì—´ ê¸°ì¤€ +2)
            c_fda_sheet_col = col_fda_B + 2
            cur_fda = (row[c_fda_sheet_col - 1] if len(row) >= c_fda_sheet_col else "").strip()
            
            # FDA ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜ ë®ì–´ì“°ê¸° ì˜µì…˜ì´ ì¼œì ¸ ìˆì„ ê²½ìš° ì—…ë°ì´íŠ¸
            if not cur_fda or overwrite:
                updates.append(Cell(row=r0 + 1, col=c_fda_sheet_col, value=FDA_CODE))

    if updates:
        with_retry(lambda: tem_ws.update_cells(updates, value_input_option="RAW"))

    print(f"C3 Done. FDA codes applied: {len(updates)} cells.")


# -------------------------------------------------------------------
# C4: (ë³´ë¥˜) ê°€ê²© ë§¤í•‘
# -------------------------------------------------------------------

def run_step_C4_prices(sh: gspread.Spreadsheet) -> None:
    # TODO: ê°€ê²© ë§¤í•‘ ë¡œì§(í•„ìš” ì‹œ êµ¬í˜„)
    print("\n[ Create ] Step C4: Prices (Skipped/Placeholder)")
    pass


# === C5 Light: Image URL ì±„ìš°ê¸° (ë¶™ì—¬ë„£ê¸°/í†µêµì²´ìš©) ===
# - Base URLì„ ì‚¬ì „ ë³´ì •í•˜ì—¬ ìŠ¬ë˜ì‹œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
# - ì‹œíŠ¸ ì ‘ê·¼ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬(try/except)ë¥¼ ì ìš©í•˜ì—¬ ì•ˆì •ì„±ì„ í™•ë³´í•©ë‹ˆë‹¤.

from typing import List, Dict, Tuple

def _key(s: str) -> str:
    """í—¤ë”/í‚¤ ì •ê·œí™”: ì†Œë¬¸ì, ê³µë°±/ì–¸ë”ìŠ¤ì½”ì–´ ì œê±°."""
    if s is None:
        return ""
    return "".join(str(s).strip().lower().replace("_", " ").split())

def _find_header_row_and_offset(tem_values: List[List[str]]) -> Tuple[int, int, Dict[str, int]]:
    """
    TEM_OUTPUTì—ì„œ í—¤ë” í–‰ê³¼ PID ì˜¤í”„ì…‹, ê·¸ë¦¬ê³  ê´€ì‹¬ ì»¬ëŸ¼ ì¸ë±ìŠ¤ ë§µì„ ì°¾ëŠ”ë‹¤.
    - PIDê°€ Aì—´ì— ìˆìœ¼ë©´ base_offset=1, ì•„ë‹ˆë©´ 0
    - ì¸ë±ìŠ¤ëŠ” í•­ìƒ 'PIDë¥¼ ì œì™¸í•œ' ê¸°ì¤€(=ë°ì´í„° ì ‘ê·¼ ì¸ë±ìŠ¤)ìœ¼ë¡œ ë³´ì •í•˜ì—¬ ë°˜í™˜í•œë‹¤.
      ì˜ˆ: ì‹¤ì œ ì‹œíŠ¸ ì»¬ëŸ¼ì´ [PID, Category, SKU, ...] ì´ë©´, ì—¬ê¸°ì„œëŠ” Categoryê°€ 0, SKUê°€ 1ì´ ëœë‹¤.
    """
    # ìš”êµ¬ ì»¬ëŸ¼(í…œí”Œë¦¿ ê¸°ì¤€) í‚¤
    WANT = {
        "variation": {"variationintegrationno.", "variationno.", "variationintegration"},  # Variation Integration No. í¬í•¨
        "sku": {"sku"},
        "cover": {"coverimage", "coverimageurl", "cover img", "cover"},
        "ipv": {"imagepervariation", "imageurlpervariation", "image per variation"},
        # item images: item image 1..8
    }

    for r, row in enumerate(tem_values):
        if not row:
            continue
        # PID ì¡´ì¬ ì—¬ë¶€ íŒë‹¨
        first_key = _key(row[0]) if len(row) > 0 else ""
        base_offset = 1 if first_key in {"pid"} else 0

        # í—¤ë” í‚¤ ë°°ì—´ (PID ì œì™¸ ì‹œì ë¶€í„° ë§Œë“¤ê¸°)
        hdr_cells = row[base_offset:]
        keys = [_key(x) for x in hdr_cells]

        # í•„ìš”í•œ ì»¬ëŸ¼ í›„ë³´ë“¤ì„ ìŠ¤ìº”
        ix_map: Dict[str, int] = {}
        # Variation
        for i, k in enumerate(keys):
            if k in WANT["variation"]:
                ix_map["variation"] = i
                break
        # SKU
        for i, k in enumerate(keys):
            if k in WANT["sku"]:
                ix_map["sku"] = i
                break
        # Cover
        for i, k in enumerate(keys):
            if k in WANT["cover"]:
                ix_map["cover"] = i
                break
        # IPv
        for i, k in enumerate(keys):
            if k in WANT["ipv"]:
                ix_map["ipv"] = i
                break
        # Item Image 1..8
        for n in range(1, 9):
            want = _key(f"item image {n}")
            for i, k in enumerate(keys):
                if k == want:
                    ix_map[f"item{n}"] = i
                    break

        # í—¤ë”ë¡œ íŒë‹¨: ìµœì†Œí•œ Variationê³¼ (Cover/IPv/Item ì¤‘ í•˜ë‚˜)ëŠ” ìˆì–´ì•¼ í•¨
        has_variation = "variation" in ix_map
        has_any_image_col = ("cover" in ix_map) or ("ipv" in ix_map) or any(f"item{n}" in ix_map for n in range(1, 9))
        if has_variation and has_any_image_col:
            return r, base_offset, ix_map

    raise RuntimeError("TEM_OUTPUT í—¤ë” í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (Variation/ì´ë¯¸ì§€ ê´€ë ¨ ì»¬ëŸ¼ì´ ëˆ„ë½ëœ ë“¯í•©ë‹ˆë‹¤)")

def _build_details_count_by_var(collection_values: List[List[str]]) -> Dict[str, int]:
    """
    Collection ì‹œíŠ¸ì—ì„œ Variation/Details Indexë¥¼ ì½ì–´ {variation_no: dcount} ë§µì„ ë§Œë“ ë‹¤.
    - Details Index ë³„ì¹­ì„ í­ë„“ê²Œ í—ˆìš© (C2ì™€ ì¼ì¹˜ ë˜ëŠ” ê·¸ ì´ìƒ)
    """
    VAR_KEYS = {"variationintegrationno.", "variationno.", "variationintegration", "variation"}
    DET_KEYS = {
        "detailsindex", "details", "detailindex",
        "detailimagecount", "detailscount", "detailcount", "detailimages", "detailimage",
    }

    if not collection_values:
        return {}

    # í—¤ë” í–‰ íƒìƒ‰
    header_row = 0
    hdr_keys = [_key(x) for x in collection_values[header_row]]
    ix_var = ix_det = None
    for i, k in enumerate(hdr_keys):
        if ix_var is None and k in VAR_KEYS:
            ix_var = i
        if ix_det is None and k in DET_KEYS:
            ix_det = i
    if ix_var is None or ix_det is None:
        # ìµœì†Œí•œ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ì•„ì´í…œ ì´ë¯¸ì§€ë¥¼ ëª» ì±„ìš°ë¯€ë¡œ ë¹ˆ ë§µ
        return {}

    dmap: Dict[str, int] = {}
    for row in collection_values[header_row + 1:]:
        if not row or len(row) <= max(ix_var, ix_det):
            continue
        var_no = str(row[ix_var]).strip()
        det_raw = str(row[ix_det]).strip()
        if not var_no:
            continue
        try:
            dcount = int(float(det_raw)) if det_raw != "" else 0
        except ValueError:
            dcount = 0
        dcount = max(0, min(8, dcount))  # 0~8ë¡œ í´ë¨í”„
        dmap[var_no] = dcount

    return dmap

def _compose_urls(base_url: str, shop_code: str, var_no: str, sku: str) -> Dict[str, str]:
    """ê° ì´ë¯¸ì§€ ìœ í˜•ì˜ URL íŒ¨í„´ì„ ìƒì„±í•œë‹¤."""
    if not base_url:
        base_url = ""
    base = base_url.rstrip("/") + "/"

    urls = {
        "cover": f"{base}{var_no}_C_{shop_code}.jpg" if var_no and shop_code else "",
        "ipv": f"{base}{sku}.jpg" if sku else "",
        # D1..D8ì€ ì—¬ê¸°ì„œ ë§Œë“¤ì§€ ì•Šê³  í˜¸ì¶œë¶€ì—ì„œ ê°œìˆ˜ì— ë”°ë¼ ë§Œë“¦
    }
    return urls

def run_step_C5_images(
    tem_values: List[List[str]],
    collection_values: List[List[str]],
    base_url: str,
    shop_code: str,
) -> List[List[str]]:
    """
    C5: TEM_OUTPUTì˜ ì´ë¯¸ì§€ ê´€ë ¨ ì»¬ëŸ¼(cover, item 1..8, image per variation)ì„ ì¼ê´„ ì±„ìš´ë‹¤.
    - PID ì—´ ìœ ë¬´ì— ìƒê´€ì—†ì´ ì‘ë™
    - ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ë¶€ë¶„ ì—…ë°ì´íŠ¸ (ì¼ë¶€ ì»¬ëŸ¼ì´ ì—†ì–´ë„ ì‹¤íŒ¨í•˜ì§€ ì•ŠìŒ)
    - Details IndexëŠ” ë‹¤ì–‘í•œ ë³„ì¹­ì„ í—ˆìš© (C2ì™€ ìµœì†Œ ë™ì¼ ë²”ìœ„)
    - ë°˜í™˜: ìˆ˜ì •ëœ tem_values (ë™ì¼ ê°ì²´ë¥¼ ìˆ˜ì •í•˜ì—¬ ë°˜í™˜)
    """
    if not tem_values:
        return tem_values

    hdr_row, base_offset, ix_map = _find_header_row_and_offset(tem_values)
    dmap = _build_details_count_by_var(collection_values)

    # ë°ì´í„° í–‰ ë£¨í”„
    for r in range(hdr_row + 1, len(tem_values)):
        row = tem_values[r]
        # ë°ì´í„° ì ‘ê·¼ ì¸ë±ìŠ¤ëŠ” í•­ìƒ base_offset ì´í›„ë¶€í„° ì‹œì‘
        data = row[base_offset:]
        # ì•ˆì „ ê°€ë“œ
        if not data:
            continue

        # í‚¤ ê°’ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        var_no = data[ix_map["variation"]].strip() if "variation" in ix_map and ix_map["variation"] < len(data) else ""
        sku = data[ix_map["sku"]].strip() if "sku" in ix_map and ix_map["sku"] < len(data) else ""

        urls = _compose_urls(base_url, shop_code, var_no, sku)
        dcount = dmap.get(var_no, 0)

        # Cover Image
        if "cover" in ix_map and ix_map["cover"] < len(data):
            data[ix_map["cover"]] = urls["cover"]

        # Image per Variation
        if "ipv" in ix_map and ix_map["ipv"] < len(data):
            data[ix_map["ipv"]] = urls["ipv"]

        # Item Image 1..8
        for n in range(1, 9):
            key = f"item{n}"
            if key in ix_map and ix_map[key] < len(data):
                data[ix_map[key]] = f"{urls['cover'][:-len('_C_'+shop_code+'.jpg')]}_D{n}.jpg" if dcount >= n and var_no else ""

        # ë‹¤ì‹œ ì›ë³¸ í–‰ì— ì¨ë„£ê¸°
        tem_values[r] = row[:base_offset] + data

    return tem_values

# -------------------------------------------------------------------
# C6: Stock/Weight/Brand ë³´ì • (MARGIN ì‹œíŠ¸ ê¸°ë°˜)
# -------------------------------------------------------------------

def run_step_C6_stock_weight_brand(sh: gspread.Spreadsheet) -> None:
    print("\n[ Create ] Step C6: Fill Stock, Weight, Brand ...")
    tem_name = get_tem_sheet_name()
    
    try:
        tem_ws = safe_worksheet(sh, tem_name)
        tem_vals = with_retry(lambda: tem_ws.get_all_values()) or []
    except WorksheetNotFound:
        print(f"[C6] {tem_name} íƒ­ ì—†ìŒ. Step C1/C2 ì„ í–‰ í•„ìš”.")
        return

    if not tem_vals:
        print("[C6] TEM_OUTPUT ë¹„ì–´ ìˆìŒ.")
        return

    # 1) MARGIN ì‹œíŠ¸ ë¡œë“œ (SKU â†” Weight)
    sku_to_weight: Dict[str, str] = {}
    try:
        mg_ws = safe_worksheet(sh, "MARGIN")
        mg_vals = with_retry(lambda: mg_ws.get_all_values()) or []
        if len(mg_vals) >= 2:
            idx_mg_sku = _pick_index_by_candidates(mg_vals[0], ["sku", "seller_sku"])
            idx_mg_weight = _pick_index_by_candidates(mg_vals[0], ["weight", "package weight"])
            if idx_mg_sku != -1 and idx_mg_weight != -1:
                for r in range(1, len(mg_vals)):
                    row = mg_vals[r]
                    sku = (row[idx_mg_sku] if idx_mg_sku < len(row) else "").strip()
                    weight = (row[idx_mg_weight] if idx_mg_weight < len(row) else "").strip()
                    if sku and weight:
                        sku_to_weight[sku] = weight
    except WorksheetNotFound:
        print("[C6] MARGIN ì‹œíŠ¸ ì—†ìŒ â†’ Weight ë§¤í•‘ ê±´ë„ˆëœ€.")
    except Exception as e:
        print(f"[C6] MARGIN ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}. Weight ë§¤í•‘ ê±´ë„ˆëœ€.")

    updates: List[Cell] = []
    cur_headers = None
    idx_t_pid = idx_t_sku = idx_t_stock = idx_t_weight = idx_t_brand = -1

    for r0, row in enumerate(tem_vals):
        # í—¤ë” í–‰ ì°¾ê¸° (PID, Category, ...)
        if (row[1] if len(row) > 1 else "").strip().lower() == "category":
            cur_headers = [header_key(h) for h in row[1:]]
            
            # PID ì»¬ëŸ¼ì€ TEM_OUTPUT Aì—´ì— ìˆìœ¼ë¯€ë¡œ 0ë²ˆì§¸ ì¸ë±ìŠ¤ë¥¼ ì°¾ìŒ
            idx_t_pid = _find_col_index([header_key(row[0])], "pid")
            
            # ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì€ TEM_OUTPUT Bì—´(ì¸ë±ìŠ¤ 1)ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ Bì—´ë¶€í„° í—¤ë” ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ ì°¾ìŒ
            idx_t_sku = _find_col_index(cur_headers, "sku")
            idx_t_stock = _find_col_index(cur_headers, "stock")
            idx_t_weight = _find_col_index(cur_headers, "weight")
            idx_t_brand = _find_col_index(cur_headers, "brand")
            continue
            
        if not cur_headers or idx_t_sku == -1:
            continue

        # SKU ì¶”ì¶œ (ì‹œíŠ¸ ì¸ë±ìŠ¤: PID=Aì—´, Category=Bì—´, SKU=Cì—´... -> í—¤ë” ì¸ë±ìŠ¤ + 2)
        sku = (row[idx_t_sku + 1] if len(row) > idx_t_sku + 1 else "").strip()
        if not sku:
            # SKUê°€ ì—†ëŠ” í–‰ì€ ê±´ë„ˆëœ€ (Variationë„ SKUê°€ í•„ìˆ˜ë¡œ ìˆì–´ì•¼í•¨)
            continue

        # Stock = 1000 (stock ì»¬ëŸ¼ì˜ ì‹œíŠ¸ ì¸ë±ìŠ¤: í—¤ë” ì¸ë±ìŠ¤ + 2)
        if idx_t_stock != -1:
            val = "1000"
            c_stock_sheet_col = idx_t_stock + 2
            cur = (row[c_stock_sheet_col - 1] if len(row) >= c_stock_sheet_col else "").strip()
            if cur != val:
                updates.append(Cell(row=r0 + 1, col=c_stock_sheet_col, value=val))

        # Brand = 0
        if idx_t_brand != -1:
            val = "0"
            c_brand_sheet_col = idx_t_brand + 2
            cur = (row[c_brand_sheet_col - 1] if len(row) >= c_brand_sheet_col else "").strip()
            if cur != val:
                updates.append(Cell(row=r0 + 1, col=c_brand_sheet_col, value=val))

        # Weight = MARGIN ë§¤í•‘ ì ìš©
        if idx_t_weight != -1 and sku:
            val = sku_to_weight.get(sku, "")
            if val:
                c_weight_sheet_col = idx_t_weight + 2
                cur = (row[c_weight_sheet_col - 1] if len(row) >= c_weight_sheet_col else "").strip()
                if cur != val:
                    updates.append(Cell(row=r0 + 1, col=c_weight_sheet_col, value=val))

    if updates:
        with_retry(lambda: tem_ws.update_cells(updates, value_input_option="RAW"))

    print(f"C6 Done. Updates: {len(updates)} cells")


# -------------------------------------------------------------------
# Export helpers (xlsx / csv)
# -------------------------------------------------------------------

def export_tem_xlsx(sh: gspread.Spreadsheet) -> Optional[BytesIO]:
    """
    TEM_OUTPUT ì‹œíŠ¸ë¥¼ TopLevel Category ë‹¨ìœ„ë¡œ ë¶„í• í•˜ì—¬ Excel(xlsx) íŒŒì¼ ë°˜í™˜.
    - Aì—´ PID ì œê±°, Category í˜•ì‹ ì •ê·œí™” í¬í•¨.
    """
    if not sh:
        return None
    tem_name = get_tem_sheet_name()
    try:
        tem_ws = safe_worksheet(sh, tem_name)
    except WorksheetNotFound:
        return None

    all_data = with_retry(lambda: tem_ws.get_all_values())
    if not all_data:
        return None

    # pandas DataFrameì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì²˜ë¦¬
    df = pd.DataFrame(all_data)
    # ëª¨ë“  ì…€ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ (í˜¼í•© íƒ€ì…ì„ ë°©ì§€)
    for c in df.columns:
        df[c] = df[c].astype(str)
    
    # í—¤ë” í–‰ ì¸ë±ìŠ¤ ì°¾ê¸° (Bì—´='Category'ì¸ í–‰)
    header_mask = df.iloc[:, 1].str.lower().eq("category")
    header_indices = df.index[header_mask].tolist()
    if not header_indices:
        print("[!] TEM_OUTPUT í—¤ë” í–‰(Category)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    output = BytesIO()
    
    # xlsxwriter ì—”ì§„ ì„í¬íŠ¸ ì‹œë„
    try:
        import xlsxwriter  # noqa: F401
        engine = "xlsxwriter"
    except ImportError:
        try:
            import openpyxl  # noqa: F401
            engine = "openpyxl"
        except ImportError:
            print("[!] xlsx ìƒì„±ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬(xlsxwriter/openpyxl)ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

    with pd.ExcelWriter(output, engine=engine) as writer:
        for i, header_index in enumerate(header_indices):
            # ë°ì´í„° ì‹œì‘ í–‰ (í—¤ë” ë‹¤ìŒ í–‰)
            start_row = header_index + 1
            # ë°ì´í„° ë í–‰ (ë‹¤ìŒ í—¤ë” í–‰ì´ê±°ë‚˜ ë°ì´í„°í”„ë ˆì„ì˜ ë)
            end_row = header_indices[i + 1] if i + 1 < len(header_indices) else len(df)
            if start_row >= end_row:
                continue

            # í—¤ë” í–‰ ë°ì´í„° (Aì—´ PID ì œì™¸, Bì—´ë¶€í„° ì‹œì‘)
            header_row = df.iloc[header_index, 1:]
            # ë°ì´í„° ì²­í¬ (Aì—´ PID ì œì™¸, Bì—´ë¶€í„° ì‹œì‘, ì‹œì‘ í–‰ë¶€í„° ë í–‰ê¹Œì§€)
            chunk_df = df.iloc[start_row:end_row, 1:].copy()

            # Category í‘œì¤€í™” (ì²« ë²ˆì§¸ ë°ì´í„° ì»¬ëŸ¼ì´ Category ì»¬ëŸ¼ì¼ ê²½ìš°)
            if not chunk_df.empty and chunk_df.shape[1] > 0 and header_key(header_row.iloc[0]) == "category":
                # ì¹´í…Œê³ ë¦¬ ì¤‘ê°„ ê³µë°± ë° í•˜ì´í”ˆ ì •ê·œí™”
                chunk_df.iloc[:, 0] = chunk_df.iloc[:, 0].astype(str).str.replace(r"\s*-\s*", "-", regex=True)

            # ì»¬ëŸ¼ ì´ë¦„ ì„¤ì • (í—¤ë” í–‰ ì‚¬ìš©)
            columns = header_row.astype(str).tolist()
            if len(columns) != chunk_df.shape[1]:
                # ì»¬ëŸ¼ ê°œìˆ˜ê°€ ë§ì§€ ì•Šì„ ê²½ìš° ë³´ì •
                if len(columns) < chunk_df.shape[1]:
                    columns += [f"col_{k}" for k in range(len(columns), chunk_df.shape[1])]
                else:
                    columns = columns[: chunk_df.shape[1]]
            chunk_df.columns = columns

            # ì‹œíŠ¸ ì´ë¦„ ì„¤ì • (Top-level Category ê¸°ë°˜)
            cat_col_name = next((c for c in columns if c.lower() == "category"), None)
            first_cat = str(chunk_df.iloc[0][cat_col_name]) if (cat_col_name and not chunk_df.empty) else "UNKNOWN"
            top_level_name = top_of_category(first_cat) or "UNKNOWN"
            # ì‹œíŠ¸ ì´ë¦„ì€ 31ì ì œí•œ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
            sheet_name = re.sub(r"[\s/\\*?:\\[\\]]", "_", str(top_level_name).title())[:31]

            # ì—‘ì…€ íŒŒì¼ì— ì“°ê¸°
            chunk_df.to_excel(writer, sheet_name=sheet_name, index=False)

    output.seek(0)
    print("Final template file generated successfully (xlsx).")
    return output


def export_tem_csv(sh: gspread.Spreadsheet) -> Optional[bytes]:
    """
    TEM_OUTPUT ì‹œíŠ¸ë¥¼ CSV(bytes)ë¡œ ë°˜í™˜.
    - Aì—´ PID ì œê±° ë° Category ì •ê·œí™” í¬í•¨.
    """
    if not sh:
        return None
    try:
        ws = safe_worksheet(sh, "TEM_OUTPUT")
        vals = with_retry(lambda: ws.get_all_values()) or []
        if not vals:
            return None

        processed_vals = []
        current_headers = None
        for row in vals:
            # í—¤ë” í–‰ ì°¾ê¸° (Bì—´='Category'ì¸ í–‰)
            if (row[1] if len(row) > 1 else "").strip().lower() == "category":
                current_headers = row[1:]
                processed_vals.append(current_headers)
                continue
            
            # ë°ì´í„° í–‰ ì²˜ë¦¬ (PID Aì—´ ì œê±°)
            if current_headers and len(row) > 1:
                data_row = row[1:]
                # ì¹´í…Œê³ ë¦¬ ì •ê·œí™” (Bì—´ë¶€í„° ì‹œì‘í•˜ëŠ” ë°ì´í„°ì—ì„œ 0ë²ˆì§¸ ì¸ë±ìŠ¤ëŠ” Category)
                if len(data_row) > 0 and header_key(current_headers[0]) == "category":
                    data_row[0] = re.sub(r"\s*-\s*", "-", data_row[0])
                processed_vals.append(data_row)
            elif len(row) > 0:
                # í—¤ë”ê°€ ì•„ë‹Œ í–‰ ì¤‘ ë°ì´í„°ê°€ ìˆëŠ” í–‰ (PIDë§Œ ë‚¨ì„ ê²½ìš°)
                processed_vals.append(row[1:])

        if not processed_vals:
            return None
            
        # CSV ì¸ì½”ë”© (UTF-8 with BOM)
        buf = io.StringIO()
        writer = csv.writer(buf)
        writer.writerows(processed_vals)
        return buf.getvalue().encode("utf-8-sig")
    except Exception as e:
        print(f"[WARN] TEM_OUTPUT CSV ë³€í™˜ ì‹¤íŒ¨: {e}")
        return None


# -------------------------------------------------------------------
# í˜¸í™˜ìš© ë³„ì¹­ (ê¸°ì¡´ í˜¸ì¶œë¶€ê°€ ê¸°ëŒ€í•˜ëŠ” ì´ë¦„)
# -------------------------------------------------------------------
run_c1_collect = run_step_C1
run_c2_tem = run_step_C2
run_c3_fda = run_step_C3_fda
run_c4_price = run_step_C4_prices
run_c5_images = run_step_C5_images
run_c6_swb = run_step_C6_stock_weight_brand

def run_c5_images(sh, base_url, shop_code):
    return run_step_C5_images(sh=sh, base_url=base_url, shop_code=shop_code)
